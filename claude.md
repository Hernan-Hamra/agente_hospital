# Agente Hospitalario - Grupo Pedi√°trico

## Claude Rules

### Restricciones
NO sin permiso: refactorizar, renombrar, mover archivos, cambiar l√≥gica, optimizar, eliminar c√≥digo.

### Permitido
Explicar, detectar errores (sin corregir), escribir c√≥digo SOLO si se pide.

### Plan obligatorio antes de cambios
```
1. archivo1.py - cambio A
2. archivo2.py - cambio B (depende 1)
¬øProceder?
```

---

## Stack

**LLM**: Ollama qwen2.5:3b (function calling)
**RAG**: FAISS + sentence-transformers/all-MiniLM-L6-v2
**Backend**: FastAPI
**Bot**: python-telegram-bot (memoria conversacional)
**Agente**: Function calling con tool consulta_rag

---

## Agente con Function Calling

**Archivo**: `backend/app/llm/client.py`

**M√©todo**: `generate_response_agent(query, historial, rag_callback)`

**Herramienta disponible**:
```python
consulta_rag(obra_social: str, query: str)
# Busca en documentos de ENSALUD/ASI/IOSFA
```

**Par√°metros cr√≠ticos** (L357-358, L398-399):
```python
# Primera llamada (sin RAG)
options={
    'temperature': 0.1,      # Muy determinista, menos alucinaciones
    'num_predict': 40        # Max 15 palabras (~3 tokens/palabra)
}

# Segunda llamada (post-RAG)
options={
    'temperature': 0.1,
    'num_predict': 50        # Max 20 palabras
}
```

**System Prompt** (L292-329):
- M√ÅXIMO 15 PALABRAS por respuesta
- SI NO SAB√âS ‚Üí USA consulta_rag OBLIGATORIO
- NUNCA inventes copagos, montos, especialidades
- Si RAG vac√≠o ‚Üí "No tengo esa info. ¬øAlgo m√°s?"

**Protocolo b√°sico (conocimiento built-in)**:
```
Guardia: DNI + credencial (NO orden)
Turno: orden + DNI + credencial
Internaci√≥n: orden autorizada + presupuesto
```

**Obras sociales cargadas**: ENSALUD, ASI, IOSFA
Si preguntan por otra ‚Üí "No tengo [X]. Solo ENSALUD/ASI/IOSFA"

---

## RAG Config

**Indexer** (`app/rag/indexer.py:50,72`)
```python
chunk_size = 1000
chunk_overlap = 100  # Actualizado de 50
```

**Retriever** (`app/rag/retriever.py`)
```python
# L39: Normaliza query embedding
faiss.normalize_L2(query_embedding)

# L59: Convierte inner product ‚Üí cosine similarity (0-1)
similarity = (distance + 1.0) / 2.0

# L64: Threshold RAG - descarta chunks irrelevantes
if similarity < 0.65:  # 0.65=moderado, 0.8+=muy similar
    continue
```

**Entity Extractor** (`app/rag/entity_extractor.py`)
```python
# L13: Obras sociales (ENSALUD, ASI, IOSFA + otras)

# L116-117: Fuzzy matching typos
if similarity > 0.8:  # Tolera errores ortogr√°ficos
    return value, similarity * 0.8
```

**Embeddings**
- Modelo: sentence-transformers/all-MiniLM-L6-v2
- Dim: 384
- Normalizaci√≥n: L2 (para cosine similarity)

**FAISS**
- IndexFlatIP: Inner Product con embeddings normalizados = cosine similarity
- Rango: -1 (opuestos) a +1 (id√©nticos)
- B√∫squeda exacta, no aproximada

---

## Telegram Bot

**Archivo**: `telegram_bot.py`

**Memoria conversacional**:
```python
from collections import deque
conversation_history = defaultdict(lambda: deque(maxlen=10))
```

**Payload al backend** (L67-71):
```python
payload = {
    "pregunta": user_message,
    "obra_social": None,
    "historial": list(conversation_history[chat_id]),
    "use_agent": True  # OBLIGATORIO para modo agente
}
```

---

## Archivos Cr√≠ticos

```
backend/app/
‚îú‚îÄ‚îÄ main.py                    # L215-265: Endpoint /query con rag_callback
‚îú‚îÄ‚îÄ models.py                  # L19: use_agent field
‚îú‚îÄ‚îÄ rag/
‚îÇ   ‚îú‚îÄ‚îÄ entity_extractor.py    # L13: OBRAS_SOCIALES
‚îÇ   ‚îú‚îÄ‚îÄ retriever.py           # L64: threshold cosine
‚îÇ   ‚îî‚îÄ‚îÄ indexer.py             # L50: chunk_size
‚îî‚îÄ‚îÄ llm/client.py              # L276-421: Agente function calling

telegram_bot.py                # L67: use_agent: True
scripts/index_data.py          # Reindexar FAISS
```

---

## Problemas Resueltos

### ‚úÖ Alucinaciones
**Antes**: Inventaba copagos, especialidades, montos
**Soluci√≥n**:
- System prompt: "NUNCA inventes"
- Temperature 0.1
- num_predict 40
- Si RAG vac√≠o ‚Üí "No tengo esa info"

### ‚úÖ Respuestas largas cortadas
**Antes**: 400+ caracteres, texto se cortaba
**Soluci√≥n**: L√≠mite 15 palabras, num_predict 40

### ‚úÖ Confusi√≥n guardia/turno
**Antes**: Dec√≠a "orden" para guardia
**Soluci√≥n**: Prompt expl√≠cito "Guardia: NO orden"

### ‚úÖ Invenci√≥n de obras sociales
**Antes**: Respond√≠a sobre OSDE sin tenerla
**Soluci√≥n**: Lista expl√≠cita + mensaje error

### ‚úÖ Sin memoria conversacional
**Antes**: Cada mensaje sin contexto
**Soluci√≥n**: Deque(maxlen=10) + historial en request

### ‚úÖ Lento (1:53 min/query)
**Antes**: llama3.2 muy lento
**Ahora**: qwen2.5:3b ‚Üí 30-40s queries simples

---

## Datos

**Ubicaci√≥n**: `data/obras_sociales/`
```
ensalud/*.docx
asi/2024-01-04_normas.docx
iosfa/*.docx
```

**IMPORTANTE**: Documentos NO contienen info sobre copagos espec√≠ficos por especialidad. Si agente dice montos/especialidades ‚Üí est√° ALUCINANDO.

**FAISS Index**: `backend/faiss_index/`

---

## Variables de Entorno

`backend/.env`:
```env
OLLAMA_MODEL=qwen2.5:3b
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
CHUNK_SIZE=1000
CHUNK_OVERLAP=100
TOP_K_RESULTS=5
```

---

## Comandos

```bash
# Backend
cd backend && source venv/bin/activate
python3 -m uvicorn app.main:app --reload

# Bot
python3 telegram_bot.py

# Reindexar
python scripts/index_data.py

# Test
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{"pregunta": "protocolo b√°sico", "use_agent": true}'
```

---

## Debugging

### Ver tool calls
Buscar en logs backend:
```
üîß Tool call: consulta_rag({'obra_social': 'ASI', 'query': '...'})
üìö Ejecutando RAG: ...
```

### Ver respuestas largas
```
üìù Longitud de respuesta: 307 caracteres  ‚Üê MAL (debe ser < 100)
```

### Verificar modelo
```bash
grep OLLAMA_MODEL backend/.env
# Debe ser: qwen2.5:3b
```

---

## M√©tricas de √âxito

- ‚úÖ Respuestas < 15 palabras (< 100 chars)
- ‚úÖ NO inventa obras sociales/copagos
- ‚úÖ Llama RAG cuando necesita info
- ‚úÖ "No tengo esa info" si RAG vac√≠o
- ‚úÖ Memoria conversacional (10 msgs)
- ‚úÖ < 40s queries simples, < 100s con RAG
