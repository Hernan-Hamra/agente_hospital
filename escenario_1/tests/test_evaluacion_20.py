#!/usr/bin/env python3
"""
Evaluaci√≥n completa de 20 preguntas para el bot del Grupo Pedi√°trico.
Genera informe detallado con m√©tricas de negocio y l√≠mites de Groq.

Uso: python escenario_1/tests/test_evaluacion_20.py
"""
import sys
import os
import time
import json
from pathlib import Path
from datetime import datetime
from dataclasses import dataclass, asdict
from typing import List, Dict, Any

# Setup paths
project_root = Path(__file__).parent.parent.parent
backend_path = project_root / "backend"
sys.path.insert(0, str(backend_path))
sys.path.insert(0, str(project_root))

from dotenv import load_dotenv
load_dotenv(backend_path / ".env")

# Imports del escenario (autocontenido)
from escenario_1.rag.retriever import ChromaRetriever
from escenario_1.core.entity_detector import get_entity_detector, reset_entity_detector
from escenario_1.metrics.collector import QueryMetrics
from escenario_1.llm.client import GroqClient
from escenario_1.core.router import ConsultaRouter

# Configuraci√≥n
CONFIG_PATH = str(project_root / "escenario_1" / "config")
GROQ_MODEL = "llama-3.3-70b-versatile"
DELAY_BETWEEN_QUERIES = 4  # segundos entre queries (l√≠mite Groq)


# =============================================================================
# 20 PREGUNTAS DE EVALUACI√ìN
# =============================================================================

TEST_CASES = [
    # --- ESPEC√çFICAS (valor exacto) ---
    {
        "id": 1, "tipo": "Espec√≠fica", "categoria": "Coseguro",
        "pregunta": "¬øCu√°nto cuesta la consulta con un m√©dico especialista en ENSALUD?",
        "obra_social": "ENSALUD",
        "respuesta_esperada": ["2912"],
        "dificultad": "F√°cil"
    },
    {
        "id": 2, "tipo": "Espec√≠fica", "categoria": "Coseguro",
        "pregunta": "¬øCu√°l es el coseguro de kinesiolog√≠a en ENSALUD?",
        "obra_social": "ENSALUD",
        "respuesta_esperada": ["971"],
        "dificultad": "F√°cil"
    },
    {
        "id": 3, "tipo": "Espec√≠fica", "categoria": "Coseguro",
        "pregunta": "¬øCu√°nto sale una tomograf√≠a en ENSALUD?",
        "obra_social": "ENSALUD",
        "respuesta_esperada": ["4854"],
        "dificultad": "Media"
    },
    {
        "id": 4, "tipo": "Espec√≠fica", "categoria": "Contacto",
        "pregunta": "¬øCu√°l es el tel√©fono de la mesa operativa de ASI?",
        "obra_social": "ASI",
        "respuesta_esperada": ["0810", "8274"],
        "dificultad": "F√°cil"
    },
    {
        "id": 5, "tipo": "Espec√≠fica", "categoria": "Contacto",
        "pregunta": "¬øA qu√© mail mando el censo de internados de ENSALUD?",
        "obra_social": "ENSALUD",
        "respuesta_esperada": ["auditoria@ensalud"],
        "dificultad": "Media"
    },
    {
        "id": 6, "tipo": "Espec√≠fica", "categoria": "Protocolo",
        "pregunta": "¬øCu√°nto duran las autorizaciones en ENSALUD?",
        "obra_social": "ENSALUD",
        "respuesta_esperada": ["30"],
        "dificultad": "F√°cil"
    },

    # --- GEN√âRICAS (listado completo) ---
    {
        "id": 7, "tipo": "Gen√©rica", "categoria": "Coseguro",
        "pregunta": "¬øCu√°les son los valores de coseguros de ENSALUD?",
        "obra_social": "ENSALUD",
        "respuesta_esperada": ["1553", "2912", "971"],
        "dificultad": "Media"
    },
    {
        "id": 8, "tipo": "Gen√©rica", "categoria": "Planes",
        "pregunta": "¬øQu√© planes tiene ENSALUD?",
        "obra_social": "ENSALUD",
        "respuesta_esperada": ["Delta", "Krono", "Quantum"],
        "dificultad": "Media"
    },
    {
        "id": 9, "tipo": "Gen√©rica", "categoria": "Exentos",
        "pregunta": "¬øQui√©nes no pagan coseguro en ENSALUD?",
        "obra_social": "ENSALUD",
        "respuesta_esperada": ["HIV", "Oncolog√≠a"],
        "dificultad": "Media"
    },
    {
        "id": 10, "tipo": "Gen√©rica", "categoria": "Contacto",
        "pregunta": "¬øCu√°les son los contactos de ASI?",
        "obra_social": "ASI",
        "respuesta_esperada": ["0810", "autorizaciones@asi"],
        "dificultad": "Media"
    },

    # --- DOCUMENTACI√ìN/REQUISITOS ---
    {
        "id": 11, "tipo": "Requisitos", "categoria": "Documentaci√≥n",
        "pregunta": "¬øQu√© documentos necesito para una consulta en IOSFA?",
        "obra_social": "IOSFA",
        "respuesta_esperada": ["DNI", "Validador"],
        "dificultad": "F√°cil"
    },
    {
        "id": 12, "tipo": "Requisitos", "categoria": "Documentaci√≥n",
        "pregunta": "¬øQu√© necesito para una internaci√≥n programada en IOSFA?",
        "obra_social": "IOSFA",
        "respuesta_esperada": ["DNI", "Validador", "autorizaci√≥n"],
        "dificultad": "Media"
    },
    {
        "id": 13, "tipo": "Requisitos", "categoria": "Documentaci√≥n",
        "pregunta": "¬øQu√© debo presentar para pr√°cticas en IOSFA?",
        "obra_social": "IOSFA",
        "respuesta_esperada": ["DNI", "Validador", "Bono"],
        "dificultad": "Media"
    },
    {
        "id": 14, "tipo": "Requisitos", "categoria": "Documentaci√≥n",
        "pregunta": "¬øQu√© documentaci√≥n pido para guardia en Grupo Pedi√°trico?",
        "obra_social": "GRUPO_PEDIATRICO",
        "respuesta_esperada": ["DNI", "credencial"],
        "dificultad": "F√°cil"
    },
    {
        "id": 15, "tipo": "Requisitos", "categoria": "Documentaci√≥n",
        "pregunta": "¬øQu√© necesito para una internaci√≥n de urgencia en Grupo Pedi√°trico?",
        "obra_social": "GRUPO_PEDIATRICO",
        "respuesta_esperada": ["DNI", "Denuncia"],
        "dificultad": "Media"
    },

    # --- COBERTURAS Y AUTORIZACIONES ---
    {
        "id": 16, "tipo": "Cobertura", "categoria": "Autorizaci√≥n",
        "pregunta": "¬øNecesito autorizaci√≥n para fisioterapia en ENSALUD?",
        "obra_social": "ENSALUD",
        "respuesta_esperada": ["autorizaci√≥n", "PREVIA"],
        "dificultad": "Media"
    },
    {
        "id": 17, "tipo": "Cobertura", "categoria": "Planes",
        "pregunta": "¬øEl plan Quantum de ENSALUD cubre consultas de especialidades?",
        "obra_social": "ENSALUD",
        "respuesta_esperada": ["cubre", "sin autorizaci√≥n"],
        "dificultad": "Dif√≠cil"
    },
    {
        "id": 18, "tipo": "Cobertura", "categoria": "Coseguro",
        "pregunta": "¬øEl plan Krono Plus de ENSALUD paga coseguro en consultas?",
        "obra_social": "ENSALUD",
        "respuesta_esperada": ["NO"],
        "dificultad": "Dif√≠cil"
    },

    # --- COLOQUIALES (lenguaje natural) ---
    {
        "id": 19, "tipo": "Coloquial", "categoria": "Coseguro",
        "pregunta": "¬øCu√°nto me sale ir al pediatra en ENSALUD?",
        "obra_social": "ENSALUD",
        "respuesta_esperada": ["1553"],
        "dificultad": "Media"
    },
    {
        "id": 20, "tipo": "Coloquial", "categoria": "Exentos",
        "pregunta": "¬øLos pacientes de oncolog√≠a pagan coseguro en Grupo Pedi√°trico?",
        "obra_social": "GRUPO_PEDIATRICO",
        "respuesta_esperada": ["no", "exento", "Oncol√≥gico"],
        "dificultad": "Dif√≠cil"
    },
]


# =============================================================================
# L√çMITES DE GROQ (Plan Gratuito)
# =============================================================================

GROQ_LIMITS = {
    "tokens_per_minute": 12000,
    "tokens_per_day": 100000,
    "requests_per_minute": 30,
    "requests_per_day": 1000,
    "avg_tokens_per_query": 800,  # Estimado (prompt + contexto + respuesta)
}


def calculate_groq_limits(avg_tokens: int) -> Dict[str, Any]:
    """Calcula l√≠mites operativos basados en tokens promedio por query."""
    return {
        "queries_per_minute": GROQ_LIMITS["tokens_per_minute"] // avg_tokens,
        "queries_per_hour": (GROQ_LIMITS["tokens_per_minute"] // avg_tokens) * 60,
        "queries_per_day": GROQ_LIMITS["tokens_per_day"] // avg_tokens,
        "recommended_delay_seconds": 4,
        "safe_queries_per_hour": 15 * 60 // 4,  # Con delay de 4 seg
    }


def evaluar_respuesta(test_case: Dict, respuesta: str) -> Dict[str, Any]:
    """Eval√∫a si la respuesta contiene los t√©rminos esperados."""
    respuesta_lower = respuesta.lower()

    terminos_encontrados = []
    terminos_faltantes = []

    for termino in test_case["respuesta_esperada"]:
        if termino.lower() in respuesta_lower:
            terminos_encontrados.append(termino)
        else:
            terminos_faltantes.append(termino)

    total = len(test_case["respuesta_esperada"])
    encontrados = len(terminos_encontrados)

    # Puntaje: porcentaje de t√©rminos encontrados
    puntaje = (encontrados / total) * 100 if total > 0 else 0

    return {
        "puntaje": round(puntaje, 1),
        "aprobado": puntaje >= 50,  # Al menos 50% de t√©rminos
        "terminos_encontrados": terminos_encontrados,
        "terminos_faltantes": terminos_faltantes,
        "total_esperados": total,
    }


def run_evaluation():
    """Ejecuta la evaluaci√≥n completa."""
    print("=" * 80)
    print("EVALUACI√ìN COMPLETA - 20 PREGUNTAS")
    print("Bot del Grupo Pedi√°trico - Escenario 1 (ChromaDB + Groq)")
    print("=" * 80)

    # Inicializar componentes
    print("\n[1/3] Inicializando componentes...")

    retriever = ChromaRetriever()
    print(f"   ‚úÖ ChromaDB: {retriever.collection.count()} chunks")

    llm_client = GroqClient()
    print(f"   ‚úÖ LLM: {GROQ_MODEL}")

    reset_entity_detector()
    entity_detector = get_entity_detector(f"{CONFIG_PATH}/entities.yaml")
    print(f"   ‚úÖ Entity Detector listo")

    router = ConsultaRouter(
        retriever=retriever,
        llm_client=llm_client,
        entity_detector=entity_detector,
        config_path=f"{CONFIG_PATH}/scenario.yaml"
    )
    print(f"   ‚úÖ Router listo\n")

    # Ejecutar evaluaci√≥n
    print("[2/3] Ejecutando 20 preguntas...\n")

    resultados = []
    total_tokens_input = 0
    total_tokens_output = 0
    total_latency_ms = 0

    for i, test in enumerate(TEST_CASES, 1):
        print(f"‚îÄ‚îÄ‚îÄ Pregunta {i}/20 [{test['tipo']}] [{test['dificultad']}] ‚îÄ‚îÄ‚îÄ")
        print(f"    {test['pregunta']}")

        start_time = time.time()

        try:
            metrics = QueryMetrics(query_text=test['pregunta'])
            result = router.process_query(query=test['pregunta'], metrics=metrics)

            latency_ms = (time.time() - start_time) * 1000
            respuesta = result.respuesta

            # Evaluar
            evaluacion = evaluar_respuesta(test, respuesta)

            # Acumular m√©tricas
            tokens_in = metrics.tokens_input or 0
            tokens_out = metrics.tokens_output or 0
            total_tokens_input += tokens_in
            total_tokens_output += tokens_out
            total_latency_ms += latency_ms

            status = "‚úÖ" if evaluacion["aprobado"] else "‚ùå"
            print(f"    {status} Puntaje: {evaluacion['puntaje']}/100")
            print(f"    üí¨ \"{respuesta[:80]}...\"")

            if evaluacion["terminos_faltantes"]:
                print(f"    ‚ö†Ô∏è  Faltaron: {evaluacion['terminos_faltantes']}")

            resultados.append({
                "test_case": test,
                "respuesta": respuesta,
                "evaluacion": evaluacion,
                "metricas": {
                    "tokens_input": tokens_in,
                    "tokens_output": tokens_out,
                    "latency_ms": round(latency_ms, 1),
                    "chunks_count": result.chunks_count,
                    "similarity": round(result.top_similarity, 3),
                },
                "exito": True,
            })

        except Exception as e:
            print(f"    ‚ùå Error: {str(e)}")
            resultados.append({
                "test_case": test,
                "respuesta": f"ERROR: {str(e)}",
                "evaluacion": {"puntaje": 0, "aprobado": False},
                "metricas": {},
                "exito": False,
            })

        print()

        # Delay entre queries (l√≠mite Groq)
        if i < len(TEST_CASES):
            time.sleep(DELAY_BETWEEN_QUERIES)

    # Calcular m√©tricas finales
    print("\n[3/3] Generando informe...\n")

    aprobados = sum(1 for r in resultados if r["evaluacion"]["aprobado"])
    exitosos = sum(1 for r in resultados if r["exito"])
    puntaje_promedio = sum(r["evaluacion"]["puntaje"] for r in resultados) / len(resultados)

    tokens_total = total_tokens_input + total_tokens_output
    avg_tokens = tokens_total // len(TEST_CASES) if TEST_CASES else 0
    avg_latency = total_latency_ms / len(TEST_CASES) if TEST_CASES else 0

    # L√≠mites de Groq
    groq_limits = calculate_groq_limits(avg_tokens if avg_tokens > 0 else 800)

    # Generar informe
    informe = {
        "metadata": {
            "fecha": datetime.now().isoformat(),
            "escenario": "Escenario 1 - Modo Consulta",
            "rag": "ChromaDB",
            "llm": GROQ_MODEL,
            "total_preguntas": len(TEST_CASES),
        },
        "resumen": {
            "preguntas_totales": len(TEST_CASES),
            "preguntas_exitosas": exitosos,
            "preguntas_aprobadas": aprobados,
            "puntaje_promedio": round(puntaje_promedio, 1),
            "tasa_aprobacion": round(aprobados / len(TEST_CASES) * 100, 1),
        },
        "metricas_tokens": {
            "total_tokens_input": total_tokens_input,
            "total_tokens_output": total_tokens_output,
            "total_tokens": tokens_total,
            "promedio_tokens_por_query": avg_tokens,
            "promedio_latency_ms": round(avg_latency, 1),
        },
        "limites_groq": {
            "plan": "Gratuito",
            "tokens_por_minuto": GROQ_LIMITS["tokens_per_minute"],
            "tokens_por_dia": GROQ_LIMITS["tokens_per_day"],
            "requests_por_dia": GROQ_LIMITS["requests_per_day"],
        },
        "capacidad_operativa": {
            "tokens_promedio_por_query": avg_tokens,
            "queries_maximas_por_minuto": groq_limits["queries_per_minute"],
            "queries_maximas_por_hora": groq_limits["queries_per_hour"],
            "queries_maximas_por_dia": groq_limits["queries_per_day"],
            "queries_seguras_por_hora": groq_limits["safe_queries_per_hour"],
            "delay_recomendado_segundos": DELAY_BETWEEN_QUERIES,
        },
        "por_tipo": {},
        "por_dificultad": {},
        "por_categoria": {},
        "por_obra_social": {},
        "resultados_detallados": resultados,
    }

    # Agrupar por tipo
    for tipo in ["Espec√≠fica", "Gen√©rica", "Requisitos", "Cobertura", "Coloquial"]:
        items = [r for r in resultados if r["test_case"]["tipo"] == tipo]
        if items:
            aprobados_tipo = sum(1 for r in items if r["evaluacion"]["aprobado"])
            informe["por_tipo"][tipo] = {
                "total": len(items),
                "aprobados": aprobados_tipo,
                "porcentaje": round(aprobados_tipo / len(items) * 100, 1),
            }

    # Agrupar por dificultad
    for dif in ["F√°cil", "Media", "Dif√≠cil"]:
        items = [r for r in resultados if r["test_case"]["dificultad"] == dif]
        if items:
            aprobados_dif = sum(1 for r in items if r["evaluacion"]["aprobado"])
            informe["por_dificultad"][dif] = {
                "total": len(items),
                "aprobados": aprobados_dif,
                "porcentaje": round(aprobados_dif / len(items) * 100, 1),
            }

    # Agrupar por categor√≠a
    categorias = set(r["test_case"]["categoria"] for r in resultados)
    for cat in categorias:
        items = [r for r in resultados if r["test_case"]["categoria"] == cat]
        aprobados_cat = sum(1 for r in items if r["evaluacion"]["aprobado"])
        informe["por_categoria"][cat] = {
            "total": len(items),
            "aprobados": aprobados_cat,
            "porcentaje": round(aprobados_cat / len(items) * 100, 1),
        }

    # Agrupar por obra social
    obras = set(r["test_case"]["obra_social"] for r in resultados)
    for os in obras:
        items = [r for r in resultados if r["test_case"]["obra_social"] == os]
        aprobados_os = sum(1 for r in items if r["evaluacion"]["aprobado"])
        informe["por_obra_social"][os] = {
            "total": len(items),
            "aprobados": aprobados_os,
            "porcentaje": round(aprobados_os / len(items) * 100, 1),
        }

    # Guardar informe JSON
    reports_dir = project_root / "escenario_1" / "reports"
    reports_dir.mkdir(exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    json_path = reports_dir / f"evaluacion_20_{timestamp}.json"

    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(informe, f, indent=2, ensure_ascii=False)

    # Imprimir resumen
    print("=" * 80)
    print("RESUMEN DE EVALUACI√ìN")
    print("=" * 80)

    print(f"\nüìä RESULTADOS GENERALES")
    print(f"   Preguntas: {exitosos}/{len(TEST_CASES)} ejecutadas")
    print(f"   Aprobadas: {aprobados}/{len(TEST_CASES)} ({informe['resumen']['tasa_aprobacion']}%)")
    print(f"   Puntaje promedio: {puntaje_promedio:.1f}/100")

    print(f"\nüìà POR TIPO DE PREGUNTA")
    for tipo, data in informe["por_tipo"].items():
        print(f"   {tipo}: {data['aprobados']}/{data['total']} ({data['porcentaje']}%)")

    print(f"\nüéöÔ∏è  POR DIFICULTAD")
    for dif, data in informe["por_dificultad"].items():
        print(f"   {dif}: {data['aprobados']}/{data['total']} ({data['porcentaje']}%)")

    print(f"\nüè¢ POR OBRA SOCIAL")
    for os, data in informe["por_obra_social"].items():
        print(f"   {os}: {data['aprobados']}/{data['total']} ({data['porcentaje']}%)")

    print(f"\nüí∞ M√âTRICAS DE TOKENS")
    print(f"   Total tokens: {tokens_total:,}")
    print(f"   Promedio por query: {avg_tokens:,} tokens")
    print(f"   Latencia promedio: {avg_latency:.0f} ms")

    print(f"\n‚ö° CAPACIDAD OPERATIVA (Groq Gratis)")
    print(f"   L√≠mite diario: {GROQ_LIMITS['tokens_per_day']:,} tokens")
    print(f"   Queries m√°ximas/d√≠a: {groq_limits['queries_per_day']}")
    print(f"   Queries seguras/hora: {groq_limits['safe_queries_per_hour']} (con delay {DELAY_BETWEEN_QUERIES}s)")
    print(f"   Queries m√°ximas/minuto: {groq_limits['queries_per_minute']}")

    print(f"\nüìÑ Informe guardado: {json_path}")
    print("=" * 80)

    return informe, json_path


if __name__ == "__main__":
    informe, path = run_evaluation()
