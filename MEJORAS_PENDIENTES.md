# Mejoras Pendientes - Agente Hospitalario

## CR√çTICO - Problemas actuales

### 1. LLM inventa informaci√≥n (alucinaciones)
**Problema**: llama3.2 (3B) es demasiado peque√±o y creativo
**Soluciones**:
- [ ] Cambiar a modelo m√°s grande: `mistral:7b-instruct` o `llama3.1:8b-instruct`
- [ ] Agregar ejemplos (few-shot) en el prompt
- [ ] Implementar validaci√≥n de respuesta antes de enviar

### 2. No detecta entidades autom√°ticamente
**Problema**: Usuario debe especificar obra social manualmente
**Soluci√≥n**: ‚úÖ IMPLEMENTADO - EntityExtractor
- [x] Detecta obra social del texto
- [x] Detecta tipo de consulta
- [x] Detecta urgencia
**Falta agregar**:
- [ ] M√°s obras sociales al diccionario (actualmente solo 8)
- [ ] Detecci√≥n de errores de tipeo (fuzzy matching)
- [ ] Sin√≥nimos y variaciones

### 3. Contexto irrelevante causa problemas
**Problema**: RAG recupera fragmentos sin relaci√≥n y LLM los usa
**Soluciones**:
- [ ] Implementar threshold de relevancia (descartar chunks con score < 0.5)
- [ ] Re-ranker despu√©s del RAG (filtrar mejor)
- [ ] Validar que el contexto sea coherente con la pregunta

---

## MEDIO - Mejoras de calidad

### 4. Chunks muy peque√±os pierden contexto
**Problema**: 500 caracteres puede partir tablas/listas
**Soluci√≥n**:
- [ ] Probar chunk_size=1000 (duplicar tama√±o)
- [ ] Usar "semantic chunking" (dividir por secciones, no por caracteres)
- [ ] Preservar estructura de tablas

### 5. No hay memoria de conversaci√≥n
**Problema**: Cada pregunta es independiente
**Soluci√≥n**:
- [ ] Implementar historial de conversaci√≥n
- [ ] Pasar √∫ltimos 3-5 mensajes al LLM
- [ ] Mantener contexto de la obra social seleccionada

### 6. Respuestas muy largas
**Problema**: El LLM genera texto excesivo
**Soluci√≥n**:
- [ ] Agregar `max_tokens` en la llamada a Ollama
- [ ] Prompt: "Respond√© en m√°ximo 200 palabras"
- [ ] Formato bullet points obligatorio

---

## BAJO - Mejoras de UX

### 7. Tiempo de respuesta lento (2 minutos)
**Opciones**:
- [ ] Cambiar a modelo m√°s chico pero mejor: `qwen2.5:3b-instruct`
- [ ] Cachear respuestas frecuentes
- [ ] GPU (si es posible)

### 8. No hay feedback de progreso
**Soluci√≥n**:
- [ ] WebSocket para streaming de respuesta
- [ ] Mensaje "Buscando en documentos..."  ‚Üí "Generando respuesta..."

### 9. No loguea consultas
**Soluci√≥n**:
- [ ] Guardar cada consulta en un archivo JSON
- [ ] M√©tricas: tiempo de respuesta, obra social, satisfacci√≥n

---

## ARQUITECTURA - Cambios estructurales

### 10. Separar retrieval de generation
**Problema**: RAG + LLM en un solo flujo
**Soluci√≥n**:
- [ ] Paso 1: Retrieval (FAISS) ‚Üí validar relevancia
- [ ] Paso 2: Solo si hay contexto relevante ‚Üí LLM
- [ ] Si no hay contexto: respuesta prefabricada

### 11. Agregar validaci√≥n de respuesta
**Antes de enviar al usuario**:
- [ ] Verificar que no mencione nombres de pacientes del contexto
- [ ] Verificar que no invente obras sociales
- [ ] Verificar que no contradiga el contexto

### 12. Sistema de templates para respuestas comunes
**Problema**: Reinventar la rueda en cada consulta
**Soluci√≥n**:
- [ ] Template "Enrolamiento gen√©rico" con variables
- [ ] Template "Documentaci√≥n requerida" con variables
- [ ] Solo usar LLM para casos complejos

---

## DATOS - Calidad de informaci√≥n

### 13. Agregar metadatos m√°s ricos
**Actualmente**: solo archivo + obra_social
**Agregar**:
- [ ] Fecha del documento (importante para vigencia)
- [ ] Versi√≥n/actualizaci√≥n
- [ ] Secci√≥n del documento (enrolamiento, derivaciones, etc.)
- [ ] Tipo de plan (si aplica)

### 14. Chunking inteligente
**Problema**: Chunks arbitrarios rompen contexto
**Soluci√≥n**:
- [ ] Dividir por secciones l√≥gicas (headers, listas)
- [ ] Mantener headers como contexto en cada chunk
- [ ] Chunks de tama√±o variable seg√∫n estructura

### 15. Agregar m√°s obras sociales
**Actualmente**: 3 obras sociales (ENSALUD, ASI, IOSFA)
**Objetivo**: 130 obras sociales
- [ ] Script para procesar lotes de PDFs
- [ ] Validaci√≥n autom√°tica de extracci√≥n
- [ ] Tests de calidad por obra social

---

## PROMPTS - Mejoras cr√≠ticas

### 16. Agregar Few-Shot Examples
**En vez de solo instrucciones, mostrar ejemplos**:

```
Ejemplo 1:
Pregunta: "Hola"
Contexto: [irrelevante]
Respuesta: "Hola! Soy un asistente administrativo..."

Ejemplo 2:
Pregunta: "Qu√© necesito para ASI?"
Contexto: [DNI, credencial, ...]
Respuesta: "üìã Documentaci√≥n requerida: DNI del paciente, ..."
```

### 17. Prompt de validaci√≥n post-generaci√≥n
**Despu√©s de generar respuesta**:
```
¬øEsta respuesta menciona informaci√≥n que NO est√° en el contexto? SI/NO
¬øEsta respuesta es √∫til para la pregunta? SI/NO
Si NO a cualquiera: RECHAZAR y regenerar
```

### 18. System prompt m√°s estricto
```
NUNCA inventes:
- Nombres de pacientes
- Fechas espec√≠ficas
- N√∫meros de tel√©fono
- Procedimientos no mencionados

Si no ten√©s informaci√≥n suficiente:
- Dec√≠ "No tengo informaci√≥n sobre [X] en mi base de datos"
- Suger√≠ contactar a la obra social
```

---

## TESTING - Asegurar calidad

### 19. Suite de tests autom√°ticos
- [ ] 50 consultas de prueba con respuestas esperadas
- [ ] Test: "Hola" ‚Üí NO debe mencionar pacientes
- [ ] Test: "Enrolar ASI" ‚Üí DEBE incluir DNI
- [ ] Test: "Horario hospital" ‚Üí "No tengo esa informaci√≥n"

### 20. Benchmarking de modelos
**Probar con diferentes modelos**:
- [ ] llama3.2:3b (actual - r√°pido pero impreciso)
- [ ] mistral:7b-instruct (balance)
- [ ] llama3.1:8b (lento pero preciso)
- [ ] qwen2.5:3b-instruct (r√°pido y preciso?)

---

## Priorizaci√≥n sugerida

**Semana 1** (Cr√≠tico):
1. Cambiar a `mistral:7b-instruct` o volver a `llama3.1:8b-instruct`
2. Agregar threshold de relevancia en RAG (0.5)
3. Agregar 100 obras sociales m√°s al EntityExtractor
4. Agregar few-shot examples al prompt

**Semana 2** (Calidad):
5. Implementar validaci√≥n de respuesta
6. Aumentar chunk_size a 1000
7. Agregar memoria de conversaci√≥n (√∫ltimos 3 mensajes)

**Semana 3** (Escalabilidad):
8. Procesar y indexar las 130 obras sociales
9. Suite de tests autom√°ticos
10. Logging de consultas

**Futuro**:
- Semantic chunking
- Re-ranker
- Sistema de templates
- M√©tricas y dashboard
