# Agente Hospitalario - Grupo PediÃ¡trico

Sistema conversacional RAG con agente autÃ³nomo para personal administrativo del hospital Grupo PediÃ¡trico.

Asiste en consultas sobre enrolamiento de pacientes y procedimientos de obras sociales con memoria conversacional.

## Stack TecnolÃ³gico

- **LLM**: Ollama (qwen2.5:3b con function calling)
- **RAG**: FAISS + sentence-transformers + cosine similarity
- **Chunking**: Pipeline offline 2 pasos (DOCX/PDF â†’ JSON intermedio â†’ JSON final)
- **Backend**: FastAPI (Python)
- **Bot**: n8n + Telegram (webhook HTTPS) O python-telegram-bot (polling)
- **Agente**: Function calling autÃ³nomo (decide cuÃ¡ndo usar RAG)
- **TÃºnel**: ngrok (para webhook mode)

## CaracterÃ­sticas Principales

- **Agente AutÃ³nomo**: Decide automÃ¡ticamente cuÃ¡ndo buscar en documentos vs responder desde conocimiento
- **Memoria Conversacional**: Mantiene contexto de conversaciÃ³n (10 mensajes)
- **Respuestas Ultra-Breves**: MÃ¡ximo 15 palabras, guiadas por preguntas
- **PrevenciÃ³n de Alucinaciones**: No inventa informaciÃ³n (copagos, especialidades, montos)
- **ValidaciÃ³n de Obras Sociales**: Solo responde sobre ENSALUD, ASI, IOSFA
- **BÃºsqueda SemÃ¡ntica**: Cosine similarity en embeddings
- **Telegram Bot**: Interfaz conversacional con historial

## Estructura del Proyecto

```
agente_hospital/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ obras_sociales/      # Documentos originales DOCX/PDF
â”‚   â”‚   â”œâ”€â”€ ensalud/
â”‚   â”‚   â”œâ”€â”€ asi/
â”‚   â”‚   â””â”€â”€ iosfa/
â”‚   â””â”€â”€ obras_sociales_json/ # Datos procesados (JSONs finales)
â”‚       â”œâ”€â”€ asi/*_FINAL.json           # 21 chunks indexados
â”‚       â”œâ”€â”€ ensalud/*_FINAL.json       # 1 chunk indexado
â”‚       â”œâ”€â”€ iosfa/*_FINAL.json         # 3 chunks indexados
â”‚       â””â”€â”€ grupo_pediatrico/*_FINAL.json  # NO indexado (protocolo base)
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py          # API endpoints + agente
â”‚   â”‚   â”œâ”€â”€ rag/             # RAG con cosine similarity
â”‚   â”‚   â”‚   â”œâ”€â”€ retriever.py
â”‚   â”‚   â”‚   â”œâ”€â”€ entity_extractor.py
â”‚   â”‚   â”‚   â””â”€â”€ indexer.py   # index_from_json (lee *_FINAL.json)
â”‚   â”‚   â””â”€â”€ llm/
â”‚   â”‚       â””â”€â”€ client.py    # Agente con function calling
â”‚   â”œâ”€â”€ faiss_index/         # Ãndice FAISS (25 documentos)
â”‚   â””â”€â”€ .env
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ convert_docs_to_json.py    # Paso 1: DOCX/PDF â†’ JSON intermedio
â”‚   â”œâ”€â”€ clean_chunks_v2.py         # Paso 2: JSON intermedio â†’ JSON final
â”‚   â”œâ”€â”€ index_data.py              # Paso 3: Reindexar FAISS
â”‚   â””â”€â”€ process_all_step1.py       # Procesar todos (paso 1)
â”œâ”€â”€ n8n/workflows/
â”‚   â””â”€â”€ telegram_agente_hospital.json  # Workflow n8n + Telegram
â””â”€â”€ telegram_bot.py          # Bot Python directo (polling mode)
```

## InstalaciÃ³n

### 1. Prerequisitos (Ubuntu/WSL)

```bash
# Instalar Python 3.10+
sudo apt update && sudo apt install python3 python3-pip python3-venv -y

# Instalar Ollama
curl -fsSL https://ollama.com/install.sh | sh

# Descargar modelo qwen2.5:3b (mejor para function calling)
ollama pull qwen2.5:3b
```

### 2. Configurar Backend

```bash
# Crear entorno virtual
cd backend
python3 -m venv venv
source venv/bin/activate

# Instalar dependencias
pip install -r requirements.txt
```

### 3. Configurar Variables de Entorno

EditÃ¡ `backend/.env`:

```env
# LLM
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=qwen2.5:3b

# Embedding
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# RAG
TOP_K_RESULTS=5

# Paths
JSON_PATH=data/obras_sociales_json  # JSONs procesados
FAISS_INDEX_PATH=./faiss_index
```

**Nota**: `CHUNK_SIZE` y `CHUNK_OVERLAP` ya no se usan (chunking ahora es offline).

### 4. Procesar y Indexar Documentos

El sistema usa un pipeline de chunking offline en 2 pasos:

```bash
# Paso 1: DOCX/PDF â†’ JSON intermedio
python scripts/convert_docs_to_json.py

# Paso 2: JSON intermedio â†’ JSON final (limpieza y validaciÃ³n)
python scripts/clean_chunks_v2.py

# Paso 3: Indexar en FAISS desde JSONs finales
python scripts/index_data.py
```

**Nota**: Los archivos `*_FINAL.json` ya estÃ¡n procesados. Solo necesitas ejecutar el Paso 3 para reindexar.

### 5. Iniciar Sistema

#### OpciÃ³n A: Con Bot Telegram directo (Python)

**Terminal 1 - Backend:**
```bash
cd backend # cd ~/proyectos/agente_hospital/backend
source venv/bin/activate
python3 -m uvicorn app.main:app --reload
```

**Terminal 2 - Bot Telegram:**
```bash
cd ~/proyectos/agente_hospital  # RaÃ­z del proyecto
source venv/bin/activate
python3 telegram_bot.py
```

#### OpciÃ³n B: Con n8n + Telegram (Webhook mode - Requiere HTTPS)

**IMPORTANTE**: El webhook de Telegram requiere HTTPS. Para desarrollo local necesitas ngrok.

**Terminal 1 - Backend:**
```bash
cd ~/proyectos/agente_hospital/backend
source venv/bin/activate
python3 -m uvicorn app.main:app --reload
```

**Terminal 2 - ngrok (tÃºnel HTTPS):**
```bash
cd ~
./ngrok http 5678
```

DespuÃ©s de lanzar ngrok, **copiÃ¡ la URL HTTPS** que aparece (ej: `https://xyz.ngrok-free.dev`)

**Terminal 3 - n8n:**
```bash
export WEBHOOK_URL=<URL_DE_NGROK>/
n8n start
# Luego accede a http://localhost:5678 y activa el workflow
```

**Ejemplo completo:**
```bash
export WEBHOOK_URL=https://ichthyotic-overbooming-makhi.ngrok-free.dev/
n8n start
```

**Nota**: La URL de ngrok cambia cada vez que lo reiniciÃ¡s (versiÃ³n gratuita). NecesitÃ¡s actualizar `WEBHOOK_URL` cada sesiÃ³n.

## Uso

### Telegram Bot

El bot mantiene memoria conversacional y responde de forma ultra-breve:

```
Usuario: hola
Bot: Hola! Soy un asistente administrativo del Grupo PediÃ¡trico. Â¿En quÃ© puedo ayudarte?

Usuario: dame el protocolo
Bot: DNI, credencial, validar. Â¿QuÃ© tipo ingreso?

Usuario: guardia
Bot: Guardia: DNI + credencial. Â¿Obra social?

Usuario: osde
Bot: No tengo OSDE. Solo ENSALUD/ASI/IOSFA

Usuario: asi
[Agente llama a RAG automÃ¡ticamente]
Bot: ASI ingreso guardia: DNI, credencial, validar. Â¿Algo mÃ¡s?
```

### API REST

#### GET /health
```bash
curl http://localhost:8000/health
```

#### POST /query (Modo Agente)
```bash
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{
    "pregunta": "protocolo bÃ¡sico",
    "use_agent": true,
    "historial": []
  }'
```

Respuesta:
```json
{
  "respuesta": "DNI, credencial, validar. Â¿QuÃ© tipo ingreso?",
  "fuentes": [],
  "obra_social_detectada": null
}
```

### DocumentaciÃ³n Swagger

http://localhost:8000/docs

## Funcionamiento del Agente

El agente con function calling decide automÃ¡ticamente:

1. **Pregunta general** â†’ Responde directamente (protocolo bÃ¡sico)
2. **Pregunta especÃ­fica de obra social** â†’ Llama `consulta_rag` tool
3. **RAG sin resultados** â†’ "No tengo esa info. Â¿Algo mÃ¡s?"
4. **Obra social no cargada** â†’ "No tengo OSDE. Solo ENSALUD/ASI/IOSFA"

**Herramientas disponibles:**
- `consulta_rag(obra_social, query)`: Busca en documentos indexados

**Reglas estrictas:**
- MÃ¡ximo 15 palabras por respuesta
- NUNCA inventar informaciÃ³n (copagos, montos, especialidades)
- SIEMPRE terminar con pregunta
- Usar RAG obligatorio si no sabe algo

## Obras Sociales Incluidas

1. **ENSALUD** - 10 planes + planes corporativos deportes
2. **ASI** - MÃºltiples planes (100, 200, 250, 300, 350, 400, 450, Evolution, Exclusive)
3. **IOSFA** - Checklist especÃ­fico

## ActualizaciÃ³n de Datos

### Agregar Nuevo Documento de Obra Social

**Protocolo sintÃ©tico:**

```bash
# 1. Copiar archivo DOCX/PDF a la carpeta correspondiente
cp ~/Downloads/nueva_normativa.docx data/obras_sociales/asi/

# 2. Convertir a JSON intermedio (paso 1)
python scripts/convert_docs_to_json.py

# 3. Limpiar y generar JSON final (paso 2)
python scripts/clean_chunks_v2.py

# 4. Reindexar FAISS
python scripts/index_data.py

# 5. Verificar
curl http://localhost:8000/health
# Debe mostrar el nuevo total de documentos indexados
```

**Estructura de carpetas:**
```
data/obras_sociales/
â”œâ”€â”€ asi/nueva_normativa.docx          # 1. Poner archivo aquÃ­
â”œâ”€â”€ ensalud/
â””â”€â”€ iosfa/

data/obras_sociales_json/
â”œâ”€â”€ asi/nueva_normativa_chunks.json   # 2. Generado por paso 1
â”œâ”€â”€ asi/nueva_normativa_FINAL.json    # 3. Generado por paso 2 (ESTE se indexa)
```

**Nota**: Backend en `--reload` detecta automÃ¡ticamente el nuevo Ã­ndice FAISS.

## ConfiguraciÃ³n Telegram

1. Crear bot con BotFather: `/newbot`
2. Obtener token
3. Configurar en `telegram_bot.py`:
```python
TELEGRAM_TOKEN = "tu_token_aqui"
BACKEND_URL = "http://localhost:8000"
```

## Troubleshooting

### Ollama no disponible
```bash
curl http://localhost:11434/api/tags
# Si falla:
ollama serve
```

### Evaluacion de Modelo incorrecto
```bash
ollama list
ollama pull qwen2.5:3b
```

### Bot inventa informaciÃ³n
- Verificar que `use_agent: True` estÃ© activado
- Revisar que `OLLAMA_MODEL=qwen2.5:3b` en `.env`
- Reducir `num_predict` en `client.py` si respuestas muy largas

### RAG no encuentra documentos
```bash
# Verificar JSONs finales procesados
ls -R data/obras_sociales_json/*_FINAL.json

# Reindexar desde JSONs
python scripts/index_data.py

# Verificar Ã­ndice FAISS
curl http://localhost:8000/health
# Debe mostrar: "documentos_indexados": 25
```

### n8n webhook "Bad request"
**Problema**: Telegram requiere HTTPS para webhooks

**SoluciÃ³n**:
```bash
# 1. Iniciar ngrok para crear tÃºnel HTTPS
cd ~ && ./ngrok http 5678

# 2. Copiar URL HTTPS generada (ej: https://xyz.ngrok-free.dev)

# 3. Iniciar n8n con WEBHOOK_URL
export WEBHOOK_URL=https://<ngrok-url>/
n8n start

# 4. Activar workflow en http://localhost:5678
```

**Nota**: La URL de ngrok cambia cada vez (plan gratuito)

## Arquitectura TÃ©cnica

### Pipeline RAG

**Offline (Chunking en 2 pasos)**:
1. **Paso 1**: DOCX/PDF â†’ JSON intermedio (extracciÃ³n texto/tablas)
2. **Paso 2**: JSON intermedio â†’ JSON final (limpieza, validaciÃ³n, metadata)
3. **IndexaciÃ³n**: JSON final â†’ Embeddings â†’ FAISS (1 chunk JSON = 1 embedding)

**Runtime (Consulta)**:
1. Query â†’ Embedding
2. FAISS â†’ Cosine similarity â†’ Top-K chunks
3. Chunks â†’ LLM (con function calling)

### Agente con Function Calling
1. User query â†’ Agente analiza
2. **Si necesita RAG**: Llama `consulta_rag` tool â†’ Backend ejecuta callback â†’ RAG retrieval
3. Agente recibe contexto â†’ Genera respuesta ultra-breve
4. **Si NO necesita RAG**: Responde directo desde protocolo bÃ¡sico

### Memoria Conversacional
- Deque de 10 mensajes (user + assistant)
- Se envÃ­a historial en cada request
- Agente mantiene contexto de conversaciÃ³n

## Estado Actual (Enero 2026)

### âœ… Completado
- Pipeline chunking offline (2 pasos) con control humano
- RAG migrado de PDF/DOCX a JSON (25 chunks indexados)
- Agente con function calling funcionando correctamente
- IntegraciÃ³n n8n + Telegram con webhook HTTPS (ngrok)
- Bot Python directo con memoria conversacional
- PrevenciÃ³n de alucinaciones (num_predict ajustado)
- Cosine similarity threshold para RAG
- GRUPO_PEDIATRICO diferenciado (protocolo base vs obras sociales)

### âš ï¸ Conocido
- **Performance**: 180-200s con RAG (limitaciÃ³n hardware CPU, no GPU)
- **ngrok URL**: Cambia cada sesiÃ³n (plan gratuito)
- **Respuestas post-RAG**: MÃ¡s largas de lo ideal (~400 chars vs objetivo 100)

### ğŸ”„ En Desarrollo
- OptimizaciÃ³n de respuestas ultra-breves post-RAG
- Testing con mÃ¡s obras sociales

## PrÃ³ximos Pasos

- [ ] AÃ±adir 127 obras sociales restantes
- [ ] Implementar cachÃ© de consultas frecuentes
- [ ] Dashboard de mÃ©tricas y analytics
- [ ] DockerizaciÃ³n para deploy
- [ ] IntegraciÃ³n con sistema hospitalario
- [ ] Evaluar Groq/API cloud para mejorar performance

## Licencia
Proyecto interno - Grupo PediÃ¡trico
