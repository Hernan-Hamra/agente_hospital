# üöÄ SETUP - Agente Hospitalario

## Paso 1: Instalar Ollama

```bash
# Instalar Ollama
curl -fsSL https://ollama.com/install.sh | sh

# Verificar instalaci√≥n
ollama --version
```

## Paso 2: Descargar modelo llama3.1

```bash
# Descargar llama3.1 (4.7GB - demora ~5-15 min)
ollama pull llama3.1

# Verificar que se descarg√≥
ollama list
```

## Paso 3: Configurar backend

```bash
cd /home/hernan/proyectos/agente_hospital/backend

# Crear entorno virtual
python3 -m venv venv

# Activar entorno
source venv/bin/activate

# Instalar dependencias
pip install -r requirements.txt
```

## Paso 4: Indexar documentos

```bash
# Desde la ra√≠z del proyecto
cd /home/hernan/proyectos/agente_hospital

# Ejecutar indexaci√≥n
python scripts/index_data.py
```

Este proceso:
- Leer√° los PDFs/DOCX de `data/obras_sociales/`
- Generar√° embeddings
- Crear√° el √≠ndice FAISS
- Demora: ~5-10 minutos

## Paso 5: Iniciar backend

```bash
cd /home/hernan/proyectos/agente_hospital/backend

# Asegurate que el entorno est√© activado
source venv/bin/activate

# Iniciar servidor
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

Deber√≠as ver:
```
üè• AGENTE HOSPITALARIO - GRUPO PEDI√ÅTRICO
‚úÖ Ollama disponible en http://localhost:11434
üì¶ Modelo: llama3.1
‚úÖ √çndice cargado: XXX chunks
üöÄ Servidor listo - http://localhost:8000
```

## Paso 6: Probar el sistema

### Opci√≥n 1: Navegador
Visit√°: http://localhost:8000/docs

### Opci√≥n 2: curl
```bash
# Health check
curl http://localhost:8000/health

# Consulta de prueba
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{
    "pregunta": "¬øQu√© documentos necesito para enrolar un paciente de ENSALUD Plan Quantum?",
    "obra_social": "ENSALUD"
  }'
```

---

## üîß Troubleshooting

### Ollama no responde
```bash
# Verificar que Ollama est√© corriendo
curl http://localhost:11434/api/tags

# Si no responde, iniciarlo manualmente
ollama serve
```

### Error al indexar
```bash
# Verificar que existan los archivos
ls -lh data/obras_sociales/*/

# Verificar permisos
chmod +x scripts/index_data.py
```

### Error de dependencias Python
```bash
cd backend
source venv/bin/activate
pip install --upgrade pip
pip install -r requirements.txt
```

---

## üìä Recursos del sistema durante ejecuci√≥n

Con llama3.1 (8B) esper√°:
- **RAM usada:** ~10-12 GB
- **CPU:** 50-80% durante consultas
- **Disco:** 4.7GB (modelo) + ~500MB (√≠ndice FAISS)

---

## ‚ö° Pr√≥ximos pasos (despu√©s de probar)

1. Ajustar par√°metros en `backend/.env` si es necesario
2. Probar con llama3.2 para comparar velocidad
3. Integrar con n8n (futuro)
4. Conectar bot de Telegram (futuro)
