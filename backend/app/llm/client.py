"""
Cliente para interactuar con Ollama (LLM local)
"""
import ollama
import time
from typing import Optional


class OllamaClient:
    """Cliente para generar respuestas con Ollama"""

    def __init__(self, host: str = "http://localhost:11434", model: str = "qwen2.5:3b"):
        """
        Args:
            host: URL del servidor Ollama
            model: Nombre del modelo a usar (qwen2.5:3b para function calling)
        """
        self.host = host
        self.model = model
        self.client = ollama.Client(host=host)

        # Definir herramientas disponibles para el agente
        self.tools = [
            {
                "type": "function",
                "function": {
                    "name": "consulta_rag",
                    "description": "Busca informaci√≥n espec√≠fica en los documentos de obras sociales (ENSALUD, ASI, IOSFA). Usa esta herramienta cuando necesites requisitos, procedimientos o informaci√≥n detallada de una obra social espec√≠fica.",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "obra_social": {
                                "type": "string",
                                "description": "La obra social sobre la que buscar (ENSALUD, ASI o IOSFA)",
                                "enum": ["ENSALUD", "ASI", "IOSFA"]
                            },
                            "query": {
                                "type": "string",
                                "description": "La consulta espec√≠fica (ej: 'requisitos internaci√≥n', 'autorizaciones cirug√≠a')"
                            }
                        },
                        "required": ["query"]
                    }
                }
            }
        ]

    def is_available(self) -> bool:
        """Verifica si Ollama est√° disponible"""
        try:
            self.client.list()
            return True
        except Exception as e:
            print(f"Ollama no disponible: {e}")
            return False

    def generate_response(self, query: str, context: str, obra_social: Optional[str] = None, historial: list = None) -> str:
        """
        Genera respuesta usando el LLM

        Args:
            query: Pregunta del usuario
            context: Contexto recuperado del RAG
            obra_social: Obra social espec√≠fica (opcional)
            historial: Lista de mensajes previos [{"role": "user/assistant", "content": "..."}]

        Returns:
            Respuesta generada
        """
        if historial is None:
            historial = []
        # Construcci√≥n del prompt
        system_prompt = """Eres un asistente administrativo del Grupo Pedi√°trico (hospital).

üö® L√çMITE ESTRICTO: M√°ximo 50 palabras por respuesta üö®
üö® Si te piden "procedimiento completo", NO lo des. Pregunt√° qu√© paso espec√≠fico necesita. üö®

ESTILO OBLIGATORIO - Respuestas ultra cortas:
‚úÖ BIEN: "DNI, credencial, validar en portal. ¬øQu√© obra social?"
‚ùå MAL: "El personal debe verificar la identidad mediante presentaci√≥n del DNI"

FORMATO OBLIGATORIO para pasos:
‚Ä¢ M√°ximo 3-4 items
‚Ä¢ M√°ximo 3 palabras por item
‚Ä¢ Siempre terminar con pregunta

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
OBRAS SOCIALES EN LA BASE DE DATOS (NUNCA MENCIONES OTRAS):
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
- ENSALUD
- ASI / ASI Salud
- IOSFA

‚ö†Ô∏è PROHIBIDO: Inventar obras sociales, URLs, tel√©fonos o datos que no est√©n en el contexto.
Si preguntan por otra obra social que NO est√© en esta lista, respond√©: "Actualmente solo tengo informaci√≥n de ENSALUD, ASI e IOSFA."

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
PROTOCOLO B√ÅSICO - GRUPO PEDI√ÅTRICO (APLICA A TODAS LAS OBRAS SOCIALES)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üìã DOCUMENTACI√ìN B√ÅSICA (OBLIGATORIA EN TODO INGRESO SI CORRESPONDE):
‚Ä¢ DNI del paciente
‚Ä¢ Credencial de obra social vigente (f√≠sica/virtual/provisoria)
‚Ä¢ N√∫mero de socio y plan
‚Ä¢ Validaci√≥n de afiliaci√≥n en Portal de Prestadores
‚Ä¢ Diagn√≥stico presuntivo
‚Ä¢ Firma del socio o responsable
‚Ä¢ Aclaraci√≥n y DNI del firmante

üè• INGRESO AMBULATORIO / TURNOS:
‚Ä¢ Consultas: DNI, credencial, validaci√≥n en portal, cobro de coseguro (SI CORRESPONDE)
‚Ä¢ Pr√°cticas: orden m√©dica original con vigencia, firma, sello y diagn√≥stico legible
‚Ä¢ Alta complejidad: autorizaci√≥n y circuitos espec√≠ficos

üö® INGRESO POR GUARDIA:
‚Ä¢ DNI, credencial y validaci√≥n afiliatoria
‚Ä¢ Evaluar si corresponde coseguro o no
‚Ä¢ Si deriva en internaci√≥n, seguir protocolo de internaci√≥n

üõèÔ∏è INTERNACI√ìN DE URGENCIA:
‚Ä¢ DNI y credencial
‚Ä¢ Validaci√≥n en portal (si corresponde)
‚Ä¢ Recibo de sueldo/monotributo/seguro de desempleo (si corresponde)
‚Ä¢ Denuncia de internaci√≥n en portal o por mail

üóìÔ∏è INTERNACI√ìN PROGRAMADA / CIRUG√çA:
‚Ä¢ Orden de internaci√≥n autorizada
‚Ä¢ Presupuesto autorizado (si corresponde)
‚Ä¢ Denuncia en portal o mail seg√∫n corresponda
‚Ä¢ Circuito en conjunto con enlace

üí∞ COSEGUROS Y EXENCIONES:
‚Ä¢ EXENTOS: Guardia, PMI, Oncol√≥gicos, HIV, Discapacidad

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
C√ìMO RESPOND√âS SEG√öN EL TIPO DE CONSULTA:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

1Ô∏è‚É£ SI TE SALUDAN SIN CONSULTA ESPEC√çFICA (hola, buen d√≠a, etc.):
   ‚úÖ Respond√© SOLO: "Hola! Soy un asistente administrativo del Grupo Pedi√°trico. ¬øEn qu√© puedo ayudarte?"
   ‚ùå NO des informaci√≥n sobre procedimientos
   ‚ùå NO uses formato largo con emojis üìãüîÑ‚ö†Ô∏è

2Ô∏è‚É£ SI PREGUNTAN SOBRE VOS (qui√©n sos, qu√© hac√©s):
   Respond√© brevemente:
   "Soy un asistente administrativo del Grupo Pedi√°trico. Ayudo con:
   - Enrolamiento de pacientes
   - Requisitos de obras sociales (ENSALUD, ASI, IOSFA)
   - Procedimientos administrativos
   ¬øSobre qu√© obra social necesit√°s informaci√≥n?"

3Ô∏è‚É£ SI PREGUNTAN QU√â OBRAS SOCIALES TEN√âS:
   Respond√©: "Tengo informaci√≥n cargada de 3 obras sociales: ENSALUD, ASI e IOSFA."
   NO inventes nombres ni enlaces web.

4Ô∏è‚É£ SI PREGUNTAN SOBRE PROCEDIMIENTOS/DOCUMENTACI√ìN (GENERAL O SIN OBRA SOCIAL ESPEC√çFICA):

   ‚ö†Ô∏è IMPORTANTE: S√© BREVE y CONVERSACIONAL. NO vuelques toda la informaci√≥n.

   Respond√© en este formato:

   "Para enrollar un paciente necesit√°s primero la documentaci√≥n b√°sica:
   ‚Ä¢ DNI del paciente
   ‚Ä¢ Credencial de obra social vigente
   ‚Ä¢ Validaci√≥n en portal

   Luego depende del tipo de ingreso (guardia, turno programado, internaci√≥n, etc.).

   ¬øQu√© tipo de ingreso es? O ¬øpara qu√© obra social espec√≠fica necesit√°s los requisitos? (ENSALUD, ASI o IOSFA)"

   üëâ M√°ximo 4-5 puntos breves
   üëâ Pregunt√° qu√© necesita saber espec√≠ficamente
   üëâ NO des toda la informaci√≥n de golpe

5Ô∏è‚É£ SI PREGUNTAN SOBRE PROCEDIMIENTOS DE UNA OBRA SOCIAL ESPEC√çFICA:

   Respond√© combinando protocolo b√°sico + requisitos espec√≠ficos de esa obra social.

   Formato:

   "Para [tipo de ingreso] con [OBRA SOCIAL] necesit√°s:

   üìã Documentaci√≥n b√°sica:
   ‚Ä¢ [2-3 items principales del protocolo b√°sico]

   üìã Espec√≠fico de [OBRA SOCIAL]:
   ‚Ä¢ [2-3 requisitos principales del contexto]

   ¬øNecesit√°s detalles de alg√∫n paso en particular?"

   üëâ M√°ximo 6-7 puntos totales
   üëâ Ofrec√© profundizar si necesita m√°s detalle

5Ô∏è‚É£ SI PREGUNTAN ALGO M√âDICO (diagn√≥sticos, tratamientos, medicaci√≥n):
   Respond√©: "No puedo ayudarte con consultas m√©dicas. Soy un asistente administrativo."

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
REGLAS CR√çTICAS ANTES DE RESPONDER:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚úÖ S√â BREVE: M√°ximo 5-7 puntos por respuesta. NO vuelques toda la informaci√≥n de golpe.
‚úÖ S√â CONVERSACIONAL: Pregunt√° qu√© necesita saber espec√≠ficamente en lugar de dar todo.
‚úÖ SI el contexto NO tiene relaci√≥n con la pregunta ‚Üí NO lo uses, respond√© desde tu rol
‚úÖ SI la consulta es general (protocolo b√°sico) ‚Üí usa el PROTOCOLO B√ÅSICO de arriba
‚úÖ SI la consulta es espec√≠fica de obra social ‚Üí combina PROTOCOLO B√ÅSICO + contexto espec√≠fico
‚ùå NO inventes nombres de pacientes, fechas, obras sociales, URLs o datos
‚ùå NO mezcles requisitos de diferentes obras sociales
‚ùå NO uses fragmentos del contexto que no respondan directamente la pregunta
‚ùå NO des respuestas largas con m√°s de 7 puntos - mejor pregunt√° qu√© necesita profundizar

Respond√©s en espa√±ol, de forma clara, amable y BREVE."""

        user_prompt = f"""Contexto de la base de datos:

{context}

---

Pregunta del administrativo: {query}

IMPORTANTE - Respond√© en M√ÅXIMO 50 palabras:
‚Ä¢ S√© ultra directo (ej: "DNI, credencial, validar portal")
‚Ä¢ NO des procedimientos completos
‚Ä¢ Pregunt√° qu√© necesita saber espec√≠ficamente
‚Ä¢ NO inventes obras sociales"""

        if obra_social:
            user_prompt += f"\n\nNOTA: La consulta es espec√≠ficamente sobre la obra social: {obra_social}"

        try:
            # Construir lista de mensajes incluyendo historial
            messages = [{'role': 'system', 'content': system_prompt}]

            # Agregar historial conversacional (sin incluir el √∫ltimo mensaje del usuario)
            # Filtramos los √∫ltimos 8 mensajes (4 pares user+assistant) para no sobrecargar
            for msg in historial[-8:]:
                # Convertir mensaje (puede ser dict o Pydantic model)
                if hasattr(msg, 'role'):  # Es un objeto Pydantic
                    msg_role = msg.role
                    msg_content = msg.content
                else:  # Es un dict
                    msg_role = msg['role']
                    msg_content = msg['content']

                # No incluir el √∫ltimo mensaje del usuario (ya est√° en user_prompt)
                if msg_role == 'user' and msg_content == query:
                    continue
                messages.append({'role': msg_role, 'content': msg_content})

            # Agregar pregunta actual
            messages.append({'role': 'user', 'content': user_prompt})

            print(f"   ü§ñ Llamando a Ollama (modelo: {self.model})...")
            print(f"   üìä Historial: {len(historial)} mensajes")
            print(f"   üìä Context window: 2048 tokens")

            start_ollama = time.time()
            response = self.client.chat(
                model=self.model,
                messages=messages,
                options={
                    'num_ctx': 2048,      # Reducir contexto para mayor velocidad
                    'num_predict': 150,   # Forzar respuestas cortas sin cortarlas
                    'temperature': 0.3    # Reducir creatividad (menos hallucinations)
                }
            )
            time_ollama = time.time() - start_ollama

            print(f"   ‚è±Ô∏è  Tiempo de inferencia Ollama: {time_ollama:.3f}s")
            print(f"   üìù Longitud de respuesta: {len(response['message']['content'])} caracteres")

            return response['message']['content']

        except Exception as e:
            return f"Error al generar respuesta: {str(e)}\n\nPor favor verific√° que Ollama est√© corriendo y el modelo '{self.model}' est√© instalado."

    def generate_response_agent(self, query: str, historial: list = None, rag_callback=None) -> dict:
        """
        Genera respuesta usando el agente con function calling

        Args:
            query: Pregunta del usuario
            historial: Lista de mensajes previos
            rag_callback: Funci√≥n callback para ejecutar consulta_rag(obra_social, query)

        Returns:
            dict con {"respuesta": str, "tool_calls": list, "needs_rag": bool}
        """
        if historial is None:
            historial = []

        # System prompt para el agente
        system_prompt = """Asistente Grupo Pedi√°trico.

PROTOCOLO B√ÅSICO:
DNI, credencial, validar, firma, diagn√≥stico.

TIPOS INGRESO:
‚Ä¢ Guardia: DNI + credencial (NO orden)
‚Ä¢ Turno: orden + DNI + credencial
‚Ä¢ Internaci√≥n: orden autorizada + presupuesto

OBRAS SOCIALES: ENSALUD, ASI, IOSFA
Otra obra social ‚Üí "No tengo [X]. Solo ENSALUD/ASI/IOSFA"

üö® REGLAS CR√çTICAS:
1. M√ÅXIMO 15 PALABRAS - si te pas√°s, el sistema falla
2. SI NO SAB√âS ALGO ‚Üí USA consulta_rag OBLIGATORIO
3. NUNCA inventes info (copagos, montos, especialidades)
4. Si no est√° en tus herramientas ‚Üí "No tengo esa info. ¬øNecesit√°s otra cosa?"
5. Termin√° SIEMPRE con pregunta

üîß USA consulta_rag cuando:
- Preguntan detalles de ENSALUD/ASI/IOSFA (circuitos, autorizaciones, requisitos)
- Preguntan info que NO es protocolo b√°sico
- Cualquier duda ‚Üí mejor consultar RAG que inventar

EJEMPLOS CORRECTOS:
User: "protocolo b√°sico"
Bot: DNI, credencial, validar. ¬øQu√© tipo ingreso?

User: "guardia"
Bot: Guardia: DNI + credencial. ¬øObra social?

User: "cu√°nto es copago dermatolog√≠a"
Bot: [USA consulta_rag porque no sab√©s] ‚Üí Si RAG no tiene info ‚Üí No tengo esa info. ¬øAlgo m√°s?

User: "osde"
Bot: No tengo OSDE. Solo ENSALUD/ASI/IOSFA
"""

        # Construir mensajes
        messages = [{'role': 'system', 'content': system_prompt}]

        # Agregar historial
        for msg in historial[-8:]:
            if hasattr(msg, 'role'):
                msg_role = msg.role
                msg_content = msg.content
            else:
                msg_role = msg['role']
                msg_content = msg['content']
            messages.append({'role': msg_role, 'content': msg_content})

        # Agregar pregunta actual
        messages.append({'role': 'user', 'content': query})

        print(f"   ü§ñ Llamando a Ollama AGENTE (modelo: {self.model})...")
        print(f"   üìä Historial: {len(historial)} mensajes")

        try:
            start = time.time()
            response = self.client.chat(
                model=self.model,
                messages=messages,
                tools=self.tools,
                options={
                    'temperature': 0.1,  # M√°s determinista
                    'num_predict': 40  # Forzar 15 palabras m√°ximo (~3 tokens por palabra)
                }
            )
            elapsed = time.time() - start

            print(f"   ‚è±Ô∏è  Tiempo de inferencia: {elapsed:.3f}s")

            message = response['message']

            # Verificar si hay tool calls
            if 'tool_calls' in message and message['tool_calls']:
                tool_call = message['tool_calls'][0]
                function_name = tool_call['function']['name']
                arguments = tool_call['function']['arguments']

                print(f"   üîß Tool call: {function_name}({arguments})")

                # Si hay callback para RAG, ejecutarlo
                if function_name == 'consulta_rag' and rag_callback:
                    obra_social = arguments.get('obra_social')
                    rag_query = arguments.get('query')

                    # Ejecutar RAG
                    print(f"   üìö Ejecutando RAG: obra_social={obra_social}, query={rag_query}")
                    context = rag_callback(obra_social, rag_query)

                    # Llamar de nuevo al LLM con el resultado
                    messages.append(message)
                    messages.append({
                        'role': 'tool',
                        'content': context
                    })

                    # Segunda llamada
                    print(f"   ü§ñ Segunda llamada con resultado de RAG...")
                    start2 = time.time()
                    response2 = self.client.chat(
                        model=self.model,
                        messages=messages,
                        options={
                            'temperature': 0.1,
                            'num_predict': 200  # Respuestas completas despu√©s de RAG
                        }
                    )
                    elapsed2 = time.time() - start2
                    print(f"   ‚è±Ô∏è  Tiempo segunda llamada: {elapsed2:.3f}s")

                    return {
                        "respuesta": response2['message']['content'],
                        "tool_calls": [tool_call],
                        "needs_rag": True
                    }

                return {
                    "respuesta": f"[Herramienta {function_name} requerida pero no disponible]",
                    "tool_calls": [tool_call],
                    "needs_rag": True
                }
            else:
                # No necesita herramientas, respuesta directa
                return {
                    "respuesta": message['content'],
                    "tool_calls": [],
                    "needs_rag": False
                }

        except Exception as e:
            print(f"   ‚ùå Error en agente: {e}")
            return {
                "respuesta": f"Error: {str(e)}",
                "tool_calls": [],
                "needs_rag": False
            }

    def pull_model(self):
        """Descarga el modelo si no est√° disponible"""
        try:
            print(f"Descargando modelo {self.model}...")
            self.client.pull(self.model)
            print(f"‚úÖ Modelo {self.model} descargado correctamente")
        except Exception as e:
            print(f"‚ùå Error descargando modelo: {e}")
